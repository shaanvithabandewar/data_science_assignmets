{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNSmCVDX46vF50pQjpRuJLG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shaanvithabandewar/data_science_assignmets/blob/main/assignment_19.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWbSqvvovm3F",
        "outputId": "d87865a7-3859-4513-9ba4-bb028864827e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                Data       Labels\n",
            "0  Path: cantaloupe.srv.cs.cmu.edu!magnesium.club...  alt.atheism\n",
            "1  Newsgroups: alt.atheism\\nPath: cantaloupe.srv....  alt.atheism\n",
            "2  Path: cantaloupe.srv.cs.cmu.edu!das-news.harva...  alt.atheism\n",
            "3  Path: cantaloupe.srv.cs.cmu.edu!magnesium.club...  alt.atheism\n",
            "4  Xref: cantaloupe.srv.cs.cmu.edu alt.atheism:53...  alt.atheism\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('blogs.csv')\n",
        "\n",
        "# Inspect the data\n",
        "print(df.head())\n",
        "\n",
        "# Data cleaning: remove punctuation, convert to lowercase, remove stopwords\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Remove non-alphabetical characters and convert to lowercase\n",
        "    text = re.sub(r'[^\\w\\s]', '', text.lower())\n",
        "    # Tokenize and remove stopwords\n",
        "    tokens = word_tokenize(text)\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "# Apply the preprocess function to the \"Data\" column\n",
        "df['cleaned_text'] = df['Data'].apply(preprocess_text)\n",
        "\n",
        "# Feature extraction using TF-IDF\n",
        "tfidf = TfidfVectorizer(max_features=5000)\n",
        "X = tfidf.fit_transform(df['cleaned_text'])\n",
        "\n",
        "# Labels\n",
        "y = df['Labels']\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the Naive Bayes classifier\n",
        "nb_model = MultinomialNB()\n",
        "nb_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = nb_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print(f'Precision: {precision}')\n",
        "print(f'Recall: {recall}')\n",
        "print(f'F1 Score: {f1}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IK1W9DIswE_1",
        "outputId": "2e15c38c-114a-4e1b-cd64-23e15d6ced2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8225\n",
            "Precision: 0.8266226056714727\n",
            "Recall: 0.8225\n",
            "F1 Score: 0.8169464895382138\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "# Function to calculate sentiment\n",
        "def get_sentiment(text):\n",
        "    blob = TextBlob(text)\n",
        "    polarity = blob.sentiment.polarity\n",
        "    if polarity > 0:\n",
        "        return 'positive'\n",
        "    elif polarity < 0:\n",
        "        return 'negative'\n",
        "    else:\n",
        "        return 'neutral'\n",
        "\n",
        "# Apply sentiment analysis to the \"Data\" column\n",
        "df['sentiment'] = df['Data'].apply(get_sentiment)\n",
        "\n",
        "# Analyze sentiment distribution across categories\n",
        "sentiment_distribution = df.groupby('Labels')['sentiment'].value_counts(normalize=True).unstack()\n",
        "print(sentiment_distribution)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thvJa9oKwIf2",
        "outputId": "2eaea5d4-99fe-47f0-9c69-62b5b7d216d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentiment                 negative  positive\n",
            "Labels                                      \n",
            "alt.atheism                   0.23      0.77\n",
            "comp.graphics                 0.24      0.76\n",
            "comp.os.ms-windows.misc       0.22      0.78\n",
            "comp.sys.ibm.pc.hardware      0.20      0.80\n",
            "comp.sys.mac.hardware         0.24      0.76\n",
            "comp.windows.x                0.27      0.73\n",
            "misc.forsale                  0.16      0.84\n",
            "rec.autos                     0.17      0.83\n",
            "rec.motorcycles               0.26      0.74\n",
            "rec.sport.baseball            0.29      0.71\n",
            "rec.sport.hockey              0.34      0.66\n",
            "sci.crypt                     0.19      0.81\n",
            "sci.electronics               0.19      0.81\n",
            "sci.med                       0.29      0.71\n",
            "sci.space                     0.27      0.73\n",
            "soc.religion.christian        0.13      0.87\n",
            "talk.politics.guns            0.30      0.70\n",
            "talk.politics.mideast         0.22      0.78\n",
            "talk.politics.misc            0.22      0.78\n",
            "talk.religion.misc            0.14      0.86\n"
          ]
        }
      ]
    }
  ]
}