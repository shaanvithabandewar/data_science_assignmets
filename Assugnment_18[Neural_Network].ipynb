{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNlbj53lcrnWk8YCPqwTAT+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shaanvithabandewar/data_science_assignmets/blob/main/Assugnment_18%5BNeural_Network%5D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('Alphabets_data.csv')\n",
        "\n",
        "# Data exploration\n",
        "print(data.head())       # Display the first few rows of the dataset\n",
        "print(data.info())       # Summary of the dataset including data types and missing values\n",
        "print(data.describe())   # Descriptive statistics\n",
        "\n",
        "# Check for missing values\n",
        "print(data.isnull().sum())\n",
        "\n",
        "# Handle missing values if necessary (e.g., imputation or removal)\n",
        "# Example: data.fillna(data.mean(), inplace=True)\n",
        "\n",
        "# Separating features and target labels\n",
        "X = data.drop('letter', axis=1)  # Assuming 'letter' is the target column\n",
        "y = data['letter']\n",
        "\n",
        "# Normalize the features using StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split the dataset into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Visualizing the distribution of classes\n",
        "sns.countplot(x=y)\n",
        "plt.title('Class Distribution in Alphabets Dataset')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "YuKnVAZCSegn",
        "outputId": "ea88c68c-d9e6-4ef5-f0d0-46c2500ea6d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  letter  xbox  ybox  width  height  onpix  xbar  ybar  x2bar  y2bar  xybar  \\\n",
            "0      T     2     8      3       5      1     8    13      0      6      6   \n",
            "1      I     5    12      3       7      2    10     5      5      4     13   \n",
            "2      D     4    11      6       8      6    10     6      2      6     10   \n",
            "3      N     7    11      6       6      3     5     9      4      6      4   \n",
            "4      G     2     1      3       1      1     8     6      6      6      6   \n",
            "\n",
            "   x2ybar  xy2bar  xedge  xedgey  yedge  yedgex  \n",
            "0      10       8      0       8      0       8  \n",
            "1       3       9      2       8      4      10  \n",
            "2       3       7      3       7      3       9  \n",
            "3       4      10      6      10      2       8  \n",
            "4       5       9      1       7      5      10  \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 20000 entries, 0 to 19999\n",
            "Data columns (total 17 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   letter  20000 non-null  object\n",
            " 1   xbox    20000 non-null  int64 \n",
            " 2   ybox    20000 non-null  int64 \n",
            " 3   width   20000 non-null  int64 \n",
            " 4   height  20000 non-null  int64 \n",
            " 5   onpix   20000 non-null  int64 \n",
            " 6   xbar    20000 non-null  int64 \n",
            " 7   ybar    20000 non-null  int64 \n",
            " 8   x2bar   20000 non-null  int64 \n",
            " 9   y2bar   20000 non-null  int64 \n",
            " 10  xybar   20000 non-null  int64 \n",
            " 11  x2ybar  20000 non-null  int64 \n",
            " 12  xy2bar  20000 non-null  int64 \n",
            " 13  xedge   20000 non-null  int64 \n",
            " 14  xedgey  20000 non-null  int64 \n",
            " 15  yedge   20000 non-null  int64 \n",
            " 16  yedgex  20000 non-null  int64 \n",
            "dtypes: int64(16), object(1)\n",
            "memory usage: 2.6+ MB\n",
            "None\n",
            "               xbox          ybox         width       height         onpix  \\\n",
            "count  20000.000000  20000.000000  20000.000000  20000.00000  20000.000000   \n",
            "mean       4.023550      7.035500      5.121850      5.37245      3.505850   \n",
            "std        1.913212      3.304555      2.014573      2.26139      2.190458   \n",
            "min        0.000000      0.000000      0.000000      0.00000      0.000000   \n",
            "25%        3.000000      5.000000      4.000000      4.00000      2.000000   \n",
            "50%        4.000000      7.000000      5.000000      6.00000      3.000000   \n",
            "75%        5.000000      9.000000      6.000000      7.00000      5.000000   \n",
            "max       15.000000     15.000000     15.000000     15.00000     15.000000   \n",
            "\n",
            "               xbar          ybar         x2bar         y2bar         xybar  \\\n",
            "count  20000.000000  20000.000000  20000.000000  20000.000000  20000.000000   \n",
            "mean       6.897600      7.500450      4.628600      5.178650      8.282050   \n",
            "std        2.026035      2.325354      2.699968      2.380823      2.488475   \n",
            "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
            "25%        6.000000      6.000000      3.000000      4.000000      7.000000   \n",
            "50%        7.000000      7.000000      4.000000      5.000000      8.000000   \n",
            "75%        8.000000      9.000000      6.000000      7.000000     10.000000   \n",
            "max       15.000000     15.000000     15.000000     15.000000     15.000000   \n",
            "\n",
            "            x2ybar        xy2bar         xedge        xedgey         yedge  \\\n",
            "count  20000.00000  20000.000000  20000.000000  20000.000000  20000.000000   \n",
            "mean       6.45400      7.929000      3.046100      8.338850      3.691750   \n",
            "std        2.63107      2.080619      2.332541      1.546722      2.567073   \n",
            "min        0.00000      0.000000      0.000000      0.000000      0.000000   \n",
            "25%        5.00000      7.000000      1.000000      8.000000      2.000000   \n",
            "50%        6.00000      8.000000      3.000000      8.000000      3.000000   \n",
            "75%        8.00000      9.000000      4.000000      9.000000      5.000000   \n",
            "max       15.00000     15.000000     15.000000     15.000000     15.000000   \n",
            "\n",
            "            yedgex  \n",
            "count  20000.00000  \n",
            "mean       7.80120  \n",
            "std        1.61747  \n",
            "min        0.00000  \n",
            "25%        7.00000  \n",
            "50%        8.00000  \n",
            "75%        9.00000  \n",
            "max       15.00000  \n",
            "letter    0\n",
            "xbox      0\n",
            "ybox      0\n",
            "width     0\n",
            "height    0\n",
            "onpix     0\n",
            "xbar      0\n",
            "ybar      0\n",
            "x2bar     0\n",
            "y2bar     0\n",
            "xybar     0\n",
            "x2ybar    0\n",
            "xy2bar    0\n",
            "xedge     0\n",
            "xedgey    0\n",
            "yedge     0\n",
            "yedgex    0\n",
            "dtype: int64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# ... (your existing code to load and preprocess data)\n",
        "\n",
        "# Convert string labels to numerical representation using LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "y_train = label_encoder.fit_transform(y_train)\n",
        "y_test = label_encoder.transform(y_test)\n",
        "\n",
        "# Define the model\n",
        "model = Sequential()\n",
        "\n",
        "# Input layer and one hidden layer\n",
        "model.add(Dense(64, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "model.add(Dense(32, activation='relu'))  # Second hidden layer\n",
        "\n",
        "# Output layer with the correct number of classes\n",
        "model.add(Dense(len(label_encoder.classes_), activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=20, validation_split=0.2, batch_size=32)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test accuracy: {test_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqA-P8GsSuMl",
        "outputId": "2e2e88c3-e298-4005-a14b-cf24a27c6279"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.2881 - loss: 2.5802 - val_accuracy: 0.6725 - val_loss: 1.2023\n",
            "Epoch 2/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6983 - loss: 1.0594 - val_accuracy: 0.7516 - val_loss: 0.8844\n",
            "Epoch 3/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7762 - loss: 0.7999 - val_accuracy: 0.7909 - val_loss: 0.7399\n",
            "Epoch 4/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8145 - loss: 0.6578 - val_accuracy: 0.8122 - val_loss: 0.6527\n",
            "Epoch 5/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8321 - loss: 0.6062 - val_accuracy: 0.8325 - val_loss: 0.5848\n",
            "Epoch 6/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8478 - loss: 0.5355 - val_accuracy: 0.8462 - val_loss: 0.5323\n",
            "Epoch 7/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8584 - loss: 0.4910 - val_accuracy: 0.8562 - val_loss: 0.4972\n",
            "Epoch 8/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8714 - loss: 0.4396 - val_accuracy: 0.8681 - val_loss: 0.4655\n",
            "Epoch 9/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8808 - loss: 0.4073 - val_accuracy: 0.8775 - val_loss: 0.4368\n",
            "Epoch 10/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8872 - loss: 0.3901 - val_accuracy: 0.8822 - val_loss: 0.4119\n",
            "Epoch 11/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8949 - loss: 0.3549 - val_accuracy: 0.8853 - val_loss: 0.3920\n",
            "Epoch 12/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9036 - loss: 0.3257 - val_accuracy: 0.8913 - val_loss: 0.3730\n",
            "Epoch 13/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9076 - loss: 0.3103 - val_accuracy: 0.8916 - val_loss: 0.3677\n",
            "Epoch 14/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9087 - loss: 0.2932 - val_accuracy: 0.8997 - val_loss: 0.3443\n",
            "Epoch 15/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9172 - loss: 0.2825 - val_accuracy: 0.9003 - val_loss: 0.3335\n",
            "Epoch 16/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9207 - loss: 0.2667 - val_accuracy: 0.9019 - val_loss: 0.3214\n",
            "Epoch 17/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9213 - loss: 0.2554 - val_accuracy: 0.9084 - val_loss: 0.3144\n",
            "Epoch 18/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9302 - loss: 0.2412 - val_accuracy: 0.9050 - val_loss: 0.3130\n",
            "Epoch 19/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9294 - loss: 0.2322 - val_accuracy: 0.9137 - val_loss: 0.2939\n",
            "Epoch 20/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9345 - loss: 0.2264 - val_accuracy: 0.9134 - val_loss: 0.2932\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9183 - loss: 0.2794\n",
            "Test accuracy: 0.9169999957084656\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-tuner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4IrVua4iTLI0",
        "outputId": "ef459542-5846-42da-933f-b7e2c1cae9bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (3.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (24.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.32.3)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (13.8.0)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (3.11.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (0.12.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2024.8.30)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras->keras-tuner) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras->keras-tuner) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras->keras-tuner) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n",
            "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.4.7 kt-legacy-1.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from keras_tuner import RandomSearch # import the installed keras tuner\n",
        "\n",
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "\n",
        "    # First hidden layer\n",
        "    model.add(Dense(hp.Int('units', min_value=32, max_value=512, step=32), activation='relu', input_shape=(X_train.shape[1],)))\n",
        "\n",
        "    # Second hidden layer (optional)\n",
        "    model.add(Dense(hp.Int('units', min_value=32, max_value=512, step=32), activation='relu'))\n",
        "\n",
        "    # Output layer\n",
        "    model.add(Dense(len(y.unique()), activation='softmax'))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Use RandomSearch for hyperparameter tuning\n",
        "tuner = RandomSearch(build_model, objective='val_accuracy', max_trials=5, executions_per_trial=3, directory='my_dir')\n",
        "\n",
        "tuner.search(X_train, y_train, epochs=10, validation_split=0.2)\n",
        "\n",
        "# Get the optimal hyperparameters\n",
        "best_hps = tuner.get_best_hyperparameters()[0]\n",
        "print(f\"Best hyperparameters: {best_hps.values}\")\n",
        "\n",
        "# Train the model with the best hyperparameters\n",
        "best_model = tuner.hypermodel.build(best_hps)\n",
        "history = best_model.fit(X_train, y_train, epochs=20, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUKjn_loTSGD",
        "outputId": "d3721b26-2802-4209-bcb8-e199d222f81d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 5 Complete [00h 01m 24s]\n",
            "val_accuracy: 0.9504166642824808\n",
            "\n",
            "Best val_accuracy So Far: 0.9504166642824808\n",
            "Total elapsed time: 00h 08m 16s\n",
            "Best hyperparameters: {'units': 288, 'learning_rate': 0.001}\n",
            "Epoch 1/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5579 - loss: 1.6388 - val_accuracy: 0.8197 - val_loss: 0.6125\n",
            "Epoch 2/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8427 - loss: 0.5260 - val_accuracy: 0.8838 - val_loss: 0.4123\n",
            "Epoch 3/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8911 - loss: 0.3555 - val_accuracy: 0.9147 - val_loss: 0.3047\n",
            "Epoch 4/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9241 - loss: 0.2562 - val_accuracy: 0.9100 - val_loss: 0.2750\n",
            "Epoch 5/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9398 - loss: 0.2030 - val_accuracy: 0.9312 - val_loss: 0.2230\n",
            "Epoch 6/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.1640 - val_accuracy: 0.9362 - val_loss: 0.1982\n",
            "Epoch 7/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9582 - loss: 0.1371 - val_accuracy: 0.9384 - val_loss: 0.1901\n",
            "Epoch 8/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9600 - loss: 0.1253 - val_accuracy: 0.9403 - val_loss: 0.1793\n",
            "Epoch 9/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9686 - loss: 0.1015 - val_accuracy: 0.9475 - val_loss: 0.1615\n",
            "Epoch 10/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9748 - loss: 0.0855 - val_accuracy: 0.9491 - val_loss: 0.1595\n",
            "Epoch 11/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9760 - loss: 0.0744 - val_accuracy: 0.9431 - val_loss: 0.1770\n",
            "Epoch 12/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9772 - loss: 0.0667 - val_accuracy: 0.9509 - val_loss: 0.1635\n",
            "Epoch 13/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9787 - loss: 0.0661 - val_accuracy: 0.9516 - val_loss: 0.1459\n",
            "Epoch 14/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.9845 - loss: 0.0539 - val_accuracy: 0.9588 - val_loss: 0.1373\n",
            "Epoch 15/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9849 - loss: 0.0503 - val_accuracy: 0.9597 - val_loss: 0.1334\n",
            "Epoch 16/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9856 - loss: 0.0476 - val_accuracy: 0.9575 - val_loss: 0.1340\n",
            "Epoch 17/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9846 - loss: 0.0493 - val_accuracy: 0.9603 - val_loss: 0.1235\n",
            "Epoch 18/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9860 - loss: 0.0482 - val_accuracy: 0.9488 - val_loss: 0.1487\n",
            "Epoch 19/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9897 - loss: 0.0359 - val_accuracy: 0.9631 - val_loss: 0.1219\n",
            "Epoch 20/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9918 - loss: 0.0284 - val_accuracy: 0.9572 - val_loss: 0.1372\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from keras_tuner import RandomSearch # import the installed keras tuner\n",
        "import numpy as np # import numpy\n",
        "\n",
        "# ... rest of the code remains the same ...\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Predicting on test data\n",
        "y_pred = best_model.predict(X_test) # use the best_model variable here\n",
        "y_pred_classes = [np.argmax(element) for element in y_pred]\n",
        "\n",
        "# Evaluation metrics\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_classes))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_classes))\n",
        "\n",
        "# Accuracy, precision, recall, and F1-score are available in the classification report"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScSyHei2VsIN",
        "outputId": "b63cc26e-0e61-43af-ea19-6c705d3461ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       149\n",
            "           1       0.90      0.97      0.93       153\n",
            "           2       0.99      0.94      0.97       137\n",
            "           3       0.96      0.97      0.96       156\n",
            "           4       0.96      0.98      0.97       141\n",
            "           5       0.96      0.94      0.95       140\n",
            "           6       0.99      0.95      0.97       160\n",
            "           7       0.89      0.94      0.92       144\n",
            "           8       0.97      0.92      0.94       146\n",
            "           9       0.95      0.97      0.96       149\n",
            "          10       0.99      0.87      0.93       130\n",
            "          11       0.93      0.99      0.96       155\n",
            "          12       0.99      0.98      0.99       168\n",
            "          13       0.99      0.95      0.97       151\n",
            "          14       0.98      0.97      0.97       145\n",
            "          15       0.94      0.98      0.96       173\n",
            "          16       0.99      0.97      0.98       166\n",
            "          17       0.91      0.96      0.93       160\n",
            "          18       0.97      0.99      0.98       171\n",
            "          19       0.95      0.98      0.97       163\n",
            "          20       0.98      0.99      0.99       183\n",
            "          21       0.99      0.91      0.95       158\n",
            "          22       0.97      0.99      0.98       148\n",
            "          23       0.96      0.96      0.96       154\n",
            "          24       0.94      0.98      0.96       168\n",
            "          25       0.99      0.96      0.98       132\n",
            "\n",
            "    accuracy                           0.96      4000\n",
            "   macro avg       0.96      0.96      0.96      4000\n",
            "weighted avg       0.96      0.96      0.96      4000\n",
            "\n",
            "Confusion Matrix:\n",
            " [[148   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   1   0   0   0   0   0]\n",
            " [  0 148   0   1   1   0   0   0   0   0   0   0   0   0   0   0   0   2\n",
            "    0   0   0   0   0   0   1   0]\n",
            " [  0   0 129   0   1   0   1   0   1   0   0   2   0   0   2   0   0   0\n",
            "    0   0   0   0   0   0   1   0]\n",
            " [  0   1   0 151   0   0   0   2   0   0   0   0   0   1   0   0   0   0\n",
            "    0   1   0   0   0   0   0   0]\n",
            " [  0   1   0   0 138   0   0   0   0   0   0   1   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   1]\n",
            " [  0   0   0   0   1 131   0   0   1   0   0   0   0   0   0   6   0   0\n",
            "    0   1   0   0   0   0   0   0]\n",
            " [  0   2   0   0   1   0 152   0   0   0   0   2   0   0   0   0   0   2\n",
            "    0   0   0   1   0   0   0   0]\n",
            " [  0   3   0   0   0   0   0 136   0   0   1   0   0   0   1   1   0   1\n",
            "    0   0   0   0   0   1   0   0]\n",
            " [  0   1   0   1   0   1   0   0 134   6   0   0   0   0   0   1   0   0\n",
            "    1   0   0   0   0   1   0   0]\n",
            " [  0   0   0   0   0   1   0   0   1 145   0   1   0   0   0   0   0   1\n",
            "    0   0   0   0   0   0   0   0]\n",
            " [  0   1   0   0   0   0   0   7   0   0 113   0   0   0   0   0   0   5\n",
            "    0   0   0   0   0   4   0   0]\n",
            " [  0   0   0   0   1   0   0   0   0   0   0 153   0   0   0   0   0   0\n",
            "    1   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   1   0   0   0   0 165   0   0   0   0   0\n",
            "    0   0   0   0   2   0   0   0]\n",
            " [  0   0   0   0   0   2   0   1   0   0   0   0   1 143   0   1   0   2\n",
            "    0   0   0   0   0   0   1   0]\n",
            " [  0   0   0   3   0   0   0   1   0   1   0   0   0   0 140   0   0   0\n",
            "    0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   1   0   0   0   0   0   1   0   0   0 169   1   0\n",
            "    0   0   0   0   0   0   1   0]\n",
            " [  0   0   0   1   0   0   0   1   0   0   0   0   0   0   0   0 161   1\n",
            "    0   0   0   0   0   0   2   0]\n",
            " [  0   3   1   0   0   0   0   2   0   0   0   1   0   0   0   0   0 153\n",
            "    0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   1   0   0\n",
            "  169   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   1   1   0   0   0   0   0   0   0   0   0\n",
            "    1 160   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0 182   0   0   0   0   0]\n",
            " [  0   5   0   0   0   1   0   0   0   0   0   0   0   0   0   1   1   0\n",
            "    0   1   0 143   2   0   4   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   2   0 146   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   4   0   0   0   0   0   0\n",
            "    0   2   0   0   0 148   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   3   0   0   0   0 165   0]\n",
            " [  1   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   1\n",
            "    2   0   0   0   0   0   0 127]]\n"
          ]
        }
      ]
    }
  ]
}